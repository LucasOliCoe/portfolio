{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed28d66",
   "metadata": {},
   "source": [
    "# PREPARANDO O AMBIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea358f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.41)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sqlalchemy) (3.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sqlalchemy) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e71cc284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28e3e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd795cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\lucas\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.9.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\lucas\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "069bc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b3a12",
   "metadata": {},
   "source": [
    "# CONFIGURANDO A CONEXÃO COM O POSTGRESQL\n",
    "\n",
    "## CRIANDO A ENGINE DE CONEXÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a59e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postgresql://usuario:senha@endereco:porta/nome_do_banco\n",
    "\n",
    "usuario = \"postgres\"\n",
    "senha = \"postgres\"\n",
    "host = \"localhost\"\n",
    "porta = \"5432\"\n",
    "banco = \"dbs_ontl\"            # Cria a conexão com o banco de dados \n",
    "\n",
    "# Cria o motor de conexão\n",
    "engine = create_engine(f'postgresql://{usuario}:{senha}@{host}:{porta}/{banco}')     # Cria a engine de conexão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9cfc1",
   "metadata": {},
   "source": [
    "# LEITURA DO DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be4bcf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"C:\\\\Users\\\\lucas\\\\Downloads\\\\datatran2025\\\\datatran2025.csv\"  # Denomina o caminho do arquivo CSV como url\n",
    "df = pd.read_csv(url, sep=\";\", encoding=\"latin1\")  #Denomina o dataframe como df e faz a sua leitura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a90a4",
   "metadata": {},
   "source": [
    "# ANALISANDO O DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dd048c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id data_inversa    dia_semana   horario  uf   br     km  \\\n",
      "0  652493   2025-01-01  quarta-feira  06:20:00  SP  116    225   \n",
      "1  652519   2025-01-01  quarta-feira  07:50:00  CE  116  546,2   \n",
      "2  652522   2025-01-01  quarta-feira  08:45:00  PR  369   88,2   \n",
      "3  652544   2025-01-01  quarta-feira  11:00:00  PR  116     74   \n",
      "4  652549   2025-01-01  quarta-feira  09:30:00  MG  251    471   \n",
      "\n",
      "               municipio                            causa_acidente  \\\n",
      "0              GUARULHOS  Reação tardia ou ineficiente do condutor   \n",
      "1              PENAFORTE                          Pista esburacada   \n",
      "2      CORNELIO PROCOPIO  Reação tardia ou ineficiente do condutor   \n",
      "3  CAMPINA GRANDE DO SUL  Reação tardia ou ineficiente do condutor   \n",
      "4           FRANCISCO SA                   Velocidade Incompatível   \n",
      "\n",
      "               tipo_acidente  ... feridos_graves ilesos ignorados feridos  \\\n",
      "0                 Tombamento  ...              0      0         1       1   \n",
      "1            Colisão frontal  ...              0      1         4       1   \n",
      "2           Colisão traseira  ...              0      2         0       3   \n",
      "3  Saída de leito carroçável  ...              0      4         0       1   \n",
      "4            Colisão frontal  ...              1      1         2       2   \n",
      "\n",
      "  veiculos      latitude     longitude  regional  delegacia             uop  \n",
      "0        2  -23,48586772  -46,54075317   SPRF-SP   DEL01-SP  UOP01-DEL01-SP  \n",
      "1        6     -7,812288  -39,08333306   SPRF-CE   DEL05-CE  UOP03-DEL05-CE  \n",
      "2        2    -23,182565    -50,637228   SPRF-PR   DEL07-PR  UOP05-DEL07-PR  \n",
      "3        2  -25,36517687  -49,04223028   SPRF-PR   DEL01-PR  UOP02-DEL01-PR  \n",
      "4        4  -16,46801304  -43,43121303   SPRF-MG   DEL12-MG  UOP01-DEL12-MG  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28598 entries, 0 to 28597\n",
      "Data columns (total 30 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      28598 non-null  int64 \n",
      " 1   data_inversa            28598 non-null  object\n",
      " 2   dia_semana              28598 non-null  object\n",
      " 3   horario                 28598 non-null  object\n",
      " 4   uf                      28598 non-null  object\n",
      " 5   br                      28598 non-null  int64 \n",
      " 6   km                      28598 non-null  object\n",
      " 7   municipio               28598 non-null  object\n",
      " 8   causa_acidente          28598 non-null  object\n",
      " 9   tipo_acidente           28597 non-null  object\n",
      " 10  classificacao_acidente  28596 non-null  object\n",
      " 11  fase_dia                28598 non-null  object\n",
      " 12  sentido_via             28598 non-null  object\n",
      " 13  condicao_metereologica  28598 non-null  object\n",
      " 14  tipo_pista              28598 non-null  object\n",
      " 15  tracado_via             28598 non-null  object\n",
      " 16  uso_solo                28598 non-null  object\n",
      " 17  pessoas                 28598 non-null  int64 \n",
      " 18  mortos                  28598 non-null  int64 \n",
      " 19  feridos_leves           28598 non-null  int64 \n",
      " 20  feridos_graves          28598 non-null  int64 \n",
      " 21  ilesos                  28598 non-null  int64 \n",
      " 22  ignorados               28598 non-null  int64 \n",
      " 23  feridos                 28598 non-null  int64 \n",
      " 24  veiculos                28598 non-null  int64 \n",
      " 25  latitude                28598 non-null  object\n",
      " 26  longitude               28598 non-null  object\n",
      " 27  regional                28598 non-null  object\n",
      " 28  delegacia               28591 non-null  object\n",
      " 29  uop                     28586 non-null  object\n",
      "dtypes: int64(10), object(20)\n",
      "memory usage: 6.5+ MB\n",
      "None\n",
      "                   id data_inversa dia_semana   horario     uf            br  \\\n",
      "count    28598.000000        28598      28598     28598  28598  28598.000000   \n",
      "unique            NaN          151          7      1253     27           NaN   \n",
      "top               NaN   2025-05-10     sábado  19:00:00     MG           NaN   \n",
      "freq              NaN          264       4604       423   3644           NaN   \n",
      "mean    672070.633191          NaN        NaN       NaN    NaN    207.917407   \n",
      "std      13697.933884          NaN        NaN       NaN    NaN    128.190342   \n",
      "min     652468.000000          NaN        NaN       NaN    NaN      0.000000   \n",
      "25%     660616.250000          NaN        NaN       NaN    NaN    101.000000   \n",
      "50%     668510.500000          NaN        NaN       NaN    NaN    153.000000   \n",
      "75%     687534.750000          NaN        NaN       NaN    NaN    316.000000   \n",
      "max     699634.000000          NaN        NaN       NaN    NaN    495.000000   \n",
      "\n",
      "           km municipio                  causa_acidente     tipo_acidente  \\\n",
      "count   28598     28598                           28598             28597   \n",
      "unique   5742      1661                              69                17   \n",
      "top         3  BRASILIA  Ausência de reação do condutor  Colisão traseira   \n",
      "freq      153       401                            4307              5635   \n",
      "mean      NaN       NaN                             NaN               NaN   \n",
      "std       NaN       NaN                             NaN               NaN   \n",
      "min       NaN       NaN                             NaN               NaN   \n",
      "25%       NaN       NaN                             NaN               NaN   \n",
      "50%       NaN       NaN                             NaN               NaN   \n",
      "75%       NaN       NaN                             NaN               NaN   \n",
      "max       NaN       NaN                             NaN               NaN   \n",
      "\n",
      "        ... feridos_graves        ilesos     ignorados       feridos  \\\n",
      "count   ...   28598.000000  28598.000000  28598.000000  28598.000000   \n",
      "unique  ...            NaN           NaN           NaN           NaN   \n",
      "top     ...            NaN           NaN           NaN           NaN   \n",
      "freq    ...            NaN           NaN           NaN           NaN   \n",
      "mean    ...       0.272746      1.051053      0.387929      1.157983   \n",
      "std     ...       0.598706      1.842502      0.802318      1.115623   \n",
      "min     ...       0.000000      0.000000      0.000000      0.000000   \n",
      "25%     ...       0.000000      0.000000      0.000000      1.000000   \n",
      "50%     ...       0.000000      1.000000      0.000000      1.000000   \n",
      "75%     ...       0.000000      1.000000      1.000000      1.000000   \n",
      "max     ...      14.000000     71.000000     18.000000     49.000000   \n",
      "\n",
      "            veiculos     latitude     longitude  regional  delegacia  \\\n",
      "count   28598.000000        28598         28598     28598      28591   \n",
      "unique           NaN        26301         26285        28        153   \n",
      "top              NaN  -22,7934208  -43,46276495   SPRF-MG   DEL01-PR   \n",
      "freq             NaN           13            12      3637       1038   \n",
      "mean        1.988775          NaN           NaN       NaN        NaN   \n",
      "std         1.084231          NaN           NaN       NaN        NaN   \n",
      "min         1.000000          NaN           NaN       NaN        NaN   \n",
      "25%         1.000000          NaN           NaN       NaN        NaN   \n",
      "50%         2.000000          NaN           NaN       NaN        NaN   \n",
      "75%         2.000000          NaN           NaN       NaN        NaN   \n",
      "max        31.000000          NaN           NaN       NaN        NaN   \n",
      "\n",
      "                   uop  \n",
      "count            28586  \n",
      "unique             393  \n",
      "top     UOP01-DEL01-SC  \n",
      "freq               459  \n",
      "mean               NaN  \n",
      "std                NaN  \n",
      "min                NaN  \n",
      "25%                NaN  \n",
      "50%                NaN  \n",
      "75%                NaN  \n",
      "max                NaN  \n",
      "\n",
      "[11 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())  # Retorna as 5 primeiras linhas do dataframe\n",
    "print(df.info())  # Retorna as principais informações do dataframe\n",
    "print(df.describe(include='all'))   # Retorna um resumo estatistico de todas as colunas, incluindo as que não são do tipo int ou bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df11f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'data_inversa', 'dia_semana', 'horario', 'uf', 'br', 'km',\n",
       "       'municipio', 'causa_acidente', 'tipo_acidente',\n",
       "       'classificacao_acidente', 'fase_dia', 'sentido_via',\n",
       "       'condicao_metereologica', 'tipo_pista', 'tracado_via', 'uso_solo',\n",
       "       'pessoas', 'mortos', 'feridos_leves', 'feridos_graves', 'ilesos',\n",
       "       'ignorados', 'feridos', 'veiculos', 'latitude', 'longitude', 'regional',\n",
       "       'delegacia', 'uop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns  # Retorna os nomes das colunas do dataframe. Aqui estamos conferindo de os nomes das colunas estão padronizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b782a",
   "metadata": {},
   "source": [
    "# TRANSFORMANDO A COLUNA data_inversa EM UMA COLUNA COM DADOS DO TIPO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dadbd9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()  #Cria uma especie de backup do dataframe para começar a analise exploratoria\n",
    "df['data_inversa'] = pd.to_datetime(df['data_inversa'], format=\"%Y-%m-%d\")  #Transforma a coluna data_inversa em dados do tipo data e sinaliza o formato que a data se encontra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b7317",
   "metadata": {},
   "source": [
    "# TRANSFORMANDO A COLUNA uso_solo EM UMA COLUNA COM DADOS DO TIPO BOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d99b7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"uso_solo\"] = df[\"uso_solo\"].str.strip().str.lower().map({     #Tira os espaços em branco, transforma os caracteres em minusculo e substitui os sim e não por true e false\n",
    "    \"sim\" : True,\n",
    "    \"não\" : False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d570209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"uso_solo\"].dtype     #Confere se houve a transformação no tipo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77eed672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['225' '546,2' '88,2' ... '803,9' '533,5' '297,2']\n",
      "0      225\n",
      "1    546,2\n",
      "2     88,2\n",
      "3       74\n",
      "4      471\n",
      "5      669\n",
      "6      376\n",
      "7    207,4\n",
      "8    708,5\n",
      "9      7,4\n",
      "Name: km, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"km\"].unique())    # Confere os dados unicos presentes na coluna\n",
    "print(df[\"km\"].head(10))    # Retorna as 10 primeiras linhas da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c1f0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"km\"] = df[\"km\"].str.replace(\".\", \"\", regex=False)\n",
    "df[\"km\"] = df[\"km\"].str.replace(\",\", \".\", regex=False)         # Remove pontos de milhar e substitui a virgula por ponto, nos decimais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd6a2f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['225' '546.2' '88.2' ... '803.9' '533.5' '297.2']\n",
      "0      225\n",
      "1    546.2\n",
      "2     88.2\n",
      "3       74\n",
      "4      471\n",
      "5      669\n",
      "6      376\n",
      "7    207.4\n",
      "8    708.5\n",
      "9      7.4\n",
      "Name: km, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"km\"].unique())    \n",
    "print(df[\"km\"].head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "662a1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"km\"] = df[\"km\"].astype(float) # Transforma os dados para o tipo float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4801f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    -23,48586772\n",
      "1       -7,812288\n",
      "2      -23,182565\n",
      "3    -25,36517687\n",
      "4    -16,46801304\n",
      "Name: latitude, dtype: object\n",
      "0    -46,54075317\n",
      "1    -39,08333306\n",
      "2      -50,637228\n",
      "3    -49,04223028\n",
      "4    -43,43121303\n",
      "Name: longitude, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"latitude\"].head())\n",
    "print(df[\"longitude\"].head())     # Retorna as 5 primeiras linhas das colunas latitude e longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb439220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"latitude\"] = df[\"latitude\"].str.strip().str.replace(\",\", \".\")\n",
    "df[\"longitude\"] = df[\"longitude\"].str.strip().str.replace(\",\", \".\")       # Limpa espaços em branco e substitui as vírgulas por pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ed67acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    -23.48586772\n",
      "1       -7.812288\n",
      "2      -23.182565\n",
      "3    -25.36517687\n",
      "4    -16.46801304\n",
      "Name: latitude, dtype: object\n",
      "0    -46.54075317\n",
      "1    -39.08333306\n",
      "2      -50.637228\n",
      "3    -49.04223028\n",
      "4    -43.43121303\n",
      "Name: longitude, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"latitude\"].head())\n",
    "print(df[\"longitude\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "399a1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")    # Transforma o tipo para float e substitui os dados vazios por NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35598b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude     float64\n",
      "longitude    float64\n",
      "dtype: object\n",
      "    latitude  longitude\n",
      "0 -23.485868 -46.540753\n",
      "1  -7.812288 -39.083333\n",
      "2 -23.182565 -50.637228\n",
      "3 -25.365177 -49.042230\n",
      "4 -16.468013 -43.431213\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"latitude\", \"longitude\"]].dtypes)\n",
    "print(df[[\"latitude\", \"longitude\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1bcf1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                 int64\n",
       "data_inversa              datetime64[ns]\n",
       "dia_semana                        object\n",
       "horario                           object\n",
       "uf                                object\n",
       "br                                 int64\n",
       "km                               float64\n",
       "municipio                         object\n",
       "causa_acidente                    object\n",
       "tipo_acidente                     object\n",
       "classificacao_acidente            object\n",
       "fase_dia                          object\n",
       "sentido_via                       object\n",
       "condicao_metereologica            object\n",
       "tipo_pista                        object\n",
       "tracado_via                       object\n",
       "uso_solo                            bool\n",
       "pessoas                            int64\n",
       "mortos                             int64\n",
       "feridos_leves                      int64\n",
       "feridos_graves                     int64\n",
       "ilesos                             int64\n",
       "ignorados                          int64\n",
       "feridos                            int64\n",
       "veiculos                           int64\n",
       "latitude                         float64\n",
       "longitude                        float64\n",
       "regional                          object\n",
       "delegacia                         object\n",
       "uop                               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bbeedac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype(str).str.strip()             #Faz um loop para remover os espaços e caracteres invisiveis das colunas do tipo object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a061d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                        0\n",
      "data_inversa              0\n",
      "dia_semana                0\n",
      "horario                   0\n",
      "uf                        0\n",
      "br                        0\n",
      "km                        0\n",
      "municipio                 0\n",
      "causa_acidente            0\n",
      "tipo_acidente             0\n",
      "classificacao_acidente    0\n",
      "fase_dia                  0\n",
      "sentido_via               0\n",
      "condicao_metereologica    0\n",
      "tipo_pista                0\n",
      "tracado_via               0\n",
      "uso_solo                  0\n",
      "pessoas                   0\n",
      "mortos                    0\n",
      "feridos_leves             0\n",
      "feridos_graves            0\n",
      "ilesos                    0\n",
      "ignorados                 0\n",
      "feridos                   0\n",
      "veiculos                  0\n",
      "latitude                  0\n",
      "longitude                 0\n",
      "regional                  0\n",
      "delegacia                 0\n",
      "uop                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())        # Confere se existem valores nulos em alguma coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b08c0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)   #Remove os valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "239cd105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATENÇÃO: IDs duplicados não encontrados!\n"
     ]
    }
   ],
   "source": [
    "if df['id'].duplicated().any():\n",
    "    print('ATENÇÃO: IDs duplicados encontrados!')\n",
    "else:\n",
    "    print('ATENÇÃO: IDs duplicados não encontrados!')       # Conferindo se existem registros de ids duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a596d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():             #Cria a conexão de forma segura, garantindo que não vamos perder algo por conta de qualquer erro\n",
    "        conn.execute(text(\"\"\"\n",
    "            DELETE FROM raw.datatran2025\n",
    "            WHERE EXTRACT(YEAR FROM data_inversa) = 2025\n",
    "\"\"\"))      #Deleta os dados antigos apenas dos anos de 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efebb9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(\n",
    "    'datatran2025',    # Nome da tabela SEM o schema\n",
    "    schema='raw',                     # Schema do banco\n",
    "    con=engine,                       # Conexão\n",
    "    if_exists='append',               # Adiciona os dados (não sobrescreve)\n",
    "    index=False                       # Não carrega o índice do DataFrame como coluna\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
