# -*- coding: utf-8 -*-
"""limpeza_tratamento_churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OLHqWJnfF6y0L6GGVC-XadF3mINkWl3t
"""

import pandas as pd

dados_churn = pd.read_json('https://caelum-online-public.s3.amazonaws.com/2929-pandas/dataset-telecon.json')
dados_churn

#Percebe-se que algumas colunas possuem jsons dentro delas. Precisamos normalizar o dataframe por inteiro

import json

with open("/content/drive/MyDrive/dataset-telecon.json") as f:
  arquivo_bruto = json.load(f)

#Para usar o json_normalize precisamos do arquivo json bruto.

dados_churn = pd.json_normalize(arquivo_bruto)
dados_churn.head()

#Agora vamos analisar os tipos dos dados

dados_churn.info()

dados_churn

#Percebemos que a coluna 'conta.cobranca.Total' é uma coluna com valores numericos mas o tipo está object. Vamos transformar para float
#Mas nossa coluna não pode ser transformada por possuir valores vazios ''
#Precisamos preencher esses valores vazios

dados_churn[dados_churn['conta.cobranca.Total'] == ' ']

#Os valores vazios correspondem ao valor do aluguel mensal multiplicado pela quantidade de meses.
#Vamos selecionar as colunas referentes ao valor mensal do aluguel e o tempo usado.

dados_churn[dados_churn['conta.cobranca.Total'] == ' '][
    ['cliente.tempo_servico', 'conta.contrato', 'conta.cobranca.mensal', 'conta.cobranca.Total']
]

#Percebe-se que o periodo alugado de todos foi por 2 anos, portanto 24 meses.
#Agora precisamos pregar a coluna dos valores dos alugueis mensais e multiplicar por 24 para saber os valores vazios de 'conta.cobranca.Total'

idx = dados_churn[dados_churn['conta.cobranca.Total'] == ' '].index

#Depois de extrair os indices dos valores que possuem o valor total vazios.
#Agora podemos pegar os valores mensais e multiplicar por 24 para sabermos o valor total

dados_churn.loc[idx, 'conta.cobranca.Total'] = dados_churn.loc[idx, 'conta.cobranca.mensal'] * 24
dados_churn.loc[idx, 'conta.cobranca.Total']

#Vamos substituir os valores de 'cliente.tempo_servico' para 24

dados_churn.loc[idx, 'cliente.tempo_servico'] = 24
dados_churn.loc[idx, 'cliente.tempo_servico']

dados_churn.loc[idx][
    ['cliente.tempo_servico', 'conta.contrato', 'conta.cobranca.mensal', 'conta.cobranca.Total']
]

#Agora podemos transformar a coluna em valores numéricos

dados_churn['conta.cobranca.Total'] = dados_churn['conta.cobranca.Total'].astype(float)

dados_churn['conta.cobranca.Total'].info()

#Vamos ver os dados unicos de todas as colunas

for col in dados_churn.columns:
  print(f'Coluna {col}')
  print(f'{dados_churn[col].unique()}')
  print('=' * 30)

#Percebemos que na coluna churn, além do 'sim' e 'não', temos um valor vazio ' ', e não queremos valor vazio nessa coluna, pois não faz sentido.
#O churn diz se o cliente deixou de ser cliente ou não.

#Precisamos acessar os valores vazios da coluna churn

dados_churn.query("Churn == ''")

#Precisamos retirar esses dados do nosso dataframe, pois são informações que não precisamos.

dados_churn_sem_vazio = dados_churn[dados_churn['Churn'] != ''].copy()

#Agora que retiramos valores, os indices ficaram com valores saltados, precisamos consertar o indice.

dados_churn_sem_vazio.reset_index(drop= True, inplace= True)
dados_churn_sem_vazio

#Agora vamos tratar os valores duplicados
#Primeiramente vamos descobrir se existem valores duplicados

dados_churn_sem_vazio.duplicated()

#Por aparecer valores 'True' podemos confirmar que existem valores duplicados
#Vamos saber quantos valores duplicados existem

dados_churn_sem_vazio.duplicated().sum()

#Vamos criar um filtro dos valores duplicados

valores_duplicados = dados_churn_sem_vazio.duplicated()
valores_duplicados

dados_churn_sem_vazio[valores_duplicados]

#Como os valores são duplicados, vamos remover os valores duplicados da nossa base de dados

dados_churn_sem_vazio.drop_duplicates(inplace=True)

#Vamos confirmar se foram removidos mesmo

dados_churn_sem_vazio.duplicated()

dados_churn_sem_vazio.duplicated().sum()

#Agora vamos tratar os valores nulos.
#Primeiro vamos ver se temos valores nulos.

dados_churn_sem_vazio.isna()

#Vamos descobrir quantos valores nulos existem

dados_churn_sem_vazio.isna().sum()

dados_churn_sem_vazio.isna().sum().sum()

#Vamos ver as linhas que possuem pelo menos um valoer nulo

dados_churn_sem_vazio[dados_churn_sem_vazio.isna().any(axis=1)]

filtro_nulo = dados_churn_sem_vazio['cliente.tempo_servico'].isna()

#Vamos ajustar os valores do 'cliente.tempo_servico' que são nulos

dados_churn_sem_vazio[filtro_nulo][['cliente.tempo_servico', 'conta.cobranca.mensal', 'conta.cobranca.Total']]

#Para saber o 'cliente.tempo_servico' podemos dividir o valor de 'conta.cobranca.Total' por 'conta.cobranca.mensal'

import numpy as np

dados_churn_sem_vazio['cliente.tempo_servico'].fillna(
    np.ceil(
        dados_churn_sem_vazio['conta.cobranca.Total'] / dados_churn_sem_vazio['conta.cobranca.mensal']
    ), inplace=True
)

dados_churn_sem_vazio[filtro_nulo][['cliente.tempo_servico', 'conta.cobranca.mensal', 'conta.cobranca.Total']]

dados_churn_sem_vazio.isna().sum()

#Ao usarmos a função .fillna().sum(), podemos perceber que ainda existem elementos com valores nulos
#Precisamos limpar esses valores

colunas_dropar = ['conta.contrato', 'conta.faturamente_eletronico', 'conta.metodo_pagamento']

dados_churn_sem_vazio[colunas_dropar].isna().any(axis=1).sum()

#Temos 37 elementos com pelo menos um valor nulo, vamos usar a função .dropna() para remover os dados nulos

dados_churn_sem_vazio.dropna(subset=colunas_dropar)

dados_churn_sem_nulo = dados_churn_sem_vazio.dropna(subset=colunas_dropar).copy()
dados_churn_sem_nulo

dados_churn_sem_nulo.reset_index(drop=True, inplace=True)

#Agora vamos confirmar se ainda existe algum valor nulo

dados_churn_sem_nulo.isna().sum()

#Agora vamos tratar os outliers

dados_churn_sem_nulo.describe()

#Ao analisarmos o valor máximo da coluna 'cliente.tempo_servico' percebemos que é 1080 meses

1080/12

#Sendo que 1080 meses são 90 anos, e não faz sentido alguém assinar o serviço de telefonia por 90 anos
#Portanto, vamos limpar esses dados

import seaborn as sns

sns.boxplot(x= dados_churn_sem_nulo['cliente.tempo_servico'])

#Vamos aplicar os calculos de boxplot para descobrirmos nossos outliers

q1 = dados_churn_sem_nulo['cliente.tempo_servico'].quantile(.25)
q3 = dados_churn_sem_nulo['cliente.tempo_servico'].quantile(.75)
iqr = q3 - q1
limite_inferior = q1 - 1.5*iqr
limite_superior = q3 + 1.5*iqr

outliers_index = (dados_churn_sem_nulo['cliente.tempo_servico'] < limite_inferior) | (dados_churn_sem_nulo['cliente.tempo_servico'] > limite_superior)
outliers_index

dados_churn_sem_nulo[outliers_index]['cliente.tempo_servico']

#Agora que sabemos quem são nossos outliers, vamos substituir os valores

churn_sem_out = dados_churn_sem_nulo.copy()
churn_sem_out[outliers_index]['cliente.tempo_servico']

#Podemos perceber que temos como saber o valor do tempo correto, vamos dividir o valor total pelo valor mensal para saber quantos meses

churn_sem_out.loc[outliers_index, 'cliente.tempo_servico'] = np.ceil(
    churn_sem_out.loc[outliers_index, 'conta.cobranca.Total'] /
    churn_sem_out.loc[outliers_index, 'conta.cobranca.mensal']
)

#Agora vamos fazer o grafico boxplot para saber se ainda temos outliers

sns.boxplot(x= churn_sem_out['cliente.tempo_servico'])

churn_sem_out[outliers_index]['cliente.tempo_servico']

#Percebemos que ainda existem outliers, vamos verificar quais são

churn_sem_out [outliers_index][['cliente.tempo_servico', 'conta.cobranca.mensal', 'conta.cobranca.Total']]

#Percebemos que os valores realmente são outliers, portanto vamos remover os correspondentes do dataframe
#Primeiro vamos atualizar o nosso outliers_index

q1 = churn_sem_out['cliente.tempo_servico'].quantile(.25)
q3 = churn_sem_out['cliente.tempo_servico'].quantile(.75)
iqr = q3 - q1
limite_inferior = q1 - 1.5*iqr
limite_superior = q3 + 1.5*iqr

outliers_index = (churn_sem_out['cliente.tempo_servico'] < limite_inferior) | (churn_sem_out['cliente.tempo_servico'] > limite_superior)
outliers_index

churn_sem_out[outliers_index]

churn_sem_out = churn_sem_out[~ outliers_index]
churn_sem_out

#Agora vamos fazer o boxplot novamente para saber se ainda temos outliers

sns.boxplot(x= churn_sem_out['cliente.tempo_servico'])

#Agora vamos resetar os indices para normalizar

churn_sem_out.reset_index(drop= True, inplace= True)
churn_sem_out

#Agora vamos limpar as variáveis categóricas
#Percebemos que a coluna id_cliente não é uma coluna necessária para análise no nosso modelo de machine learning

churn_sem_out.drop('id_cliente', axis=1)

churn_sem_id = churn_sem_out.drop('id_cliente', axis=1).copy()

churn_sem_id

#Agora vamos pegar as colunas com variaveis categoricas binarias e substituir por 0 e 1
#Vamos fazer um mapeamento para determinar os valor de 'sim', 'não', 'masculino' e 'feminino'

mapeamento = {
    'nao': 0,
    'sim': 1,
    'masculino': 0,
    'feminino': 1
}

#Precisamos identificar as colunas com variaveis categoricas binarias

for col in churn_sem_id.columns:
  print(f'Coluna {col}')
  print(f'{churn_sem_id[col].unique()}')
  print('=' * 30)

#As colunas que são variaveis categoricas binarias são
#'telefone.servico_telefone', 'Churn', 'cliente.parceiro', 'cliente.dependentes', 'conta.faturamente_eletronico', 'cliente.genero'

colunas = ['telefone.servico_telefone', 'Churn', 'cliente.parceiro', 'cliente.dependentes', 'conta.faturamente_eletronico', 'cliente.genero']

churn_sem_id[colunas] = churn_sem_id[colunas].replace(mapeamento)
churn_sem_id.head()

#Vamos confirmar se os dados foram realmente alterados

for col in churn_sem_id.columns:
  print(f'Coluna {col}')
  print(f'{churn_sem_id[col].unique()}')
  print('=' * 30)

#Agora precisamos trabalhar as variaveis categoricas nominais
#One hot encoder (dummy) é uma técnica de pegar variaveis categoricas e separar cada categoria,
#sendo que 1 representa ser aquela categoria e 0 que não seja

pd.get_dummies(churn_sem_id)

churn_dummies = pd.get_dummies(churn_sem_id, dtype= int).copy()
churn_dummies.head()

#Varias colunas foram criadas
#Vamos ver quais são as colunas

churn_dummies.columns

churn_dummies.info()

#Podemos perceber que temos valores apenas tipo int e float
#Agora sim o dataframe está apto a ser usado em um modelo de machine learning